{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b46d3b5",
   "metadata": {},
   "source": [
    "Tutorial from [Neural-Networks-from-Scratch by lionelmessi6410]https://github.com/lionelmessi6410/Neural-Networks-from-Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85d1dd9",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00b5d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from tensorflow.keras.datasets.cifar10 import cifar10_data\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48219956",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea477aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(image, num_row = 2, num_col = 5):\n",
    "    image_size = int(np.sqrt(image.shape[-1]))\n",
    "    image = np.reshape(image, (image.shape[0], image_size, image_size,3))\n",
    "    fig, axes = plt.subplot(num_row, num_col, figsize = (1.5*num_col, 2* num_row))\n",
    "    for i in range(num_row*num_col):\n",
    "        ax = axes[i//num_col, i %num_col]\n",
    "        ax = imshow(image[i],cmap = 'gray', vmin = 0, vmax = 1)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def one_hot(x, k, dtype = np.float32):\n",
    "    \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
    "    return np.array(x[:, None] == np.arange(k), dtype)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb084d47",
   "metadata": {},
   "source": [
    "# Acquire Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a9fc655",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train),(X_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e32df5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 1))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06291ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "# One-hot encode labels\n",
    "num_labels = 10\n",
    "example = y_train.shape[0]\n",
    "y_train_en = one_hot(y_train.astype('int32'),num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff73deb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 70 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Training data: {} {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Test data: {} {}\".format(X_test.shape, y_test.shape))\n",
    "show_images(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c029683-f744-4145-aa94-77da54af01fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetwork():\n",
    "    def __init__(self, sizes, activation = 'sigmoid'):\n",
    "        self.sizes = sizes\n",
    "        \n",
    "        # Choose activation function\n",
    "        if activation == 'relu':\n",
    "            self.activation = self.relu\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = self.sigmoid\n",
    "        else:\n",
    "            raise ValueError(\"Activation function is currently not support, please use 'relu' or 'sigmoid' instead.\")\n",
    "\n",
    "        # save all weights \n",
    "        self.params = self.initialize()\n",
    "        # Save all intermediate values, i.e. activations        \n",
    "        self.cache = {}\n",
    "\n",
    "    def relu(self, x, derivative = False):\n",
    "        '''\n",
    "            Derivative of ReLU is a bit more complicated since it is not differentiable at x = 0\n",
    "        \n",
    "            Forward path:\n",
    "            relu(x) = max(0, x)\n",
    "            In other word,\n",
    "            relu(x) = 0, if x < 0\n",
    "                    = x, if x >= 0\n",
    "        \n",
    "            Backward path:\n",
    "            ∇relu(x) = 0, if x < 0\n",
    "                     = 1, if x >=0\n",
    "        '''\n",
    "        if derivative:\n",
    "            x = np.where(x < 0, 0, x)\n",
    "            x = np.where(x >= 0, 1, x)\n",
    "            return x\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def sigmoid(self, x, derivative = False):\n",
    "        '''\n",
    "            Forward path:\n",
    "            σ(x) = 1 / 1+exp(-z)\n",
    "            \n",
    "            Backward path:\n",
    "            ∇σ(x) = exp(-z) / (1+exp(-z))^2\n",
    "        '''\n",
    "        if derivative:\n",
    "            return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "        return 1/(1 + np.exp(-x))\n",
    "\n",
    "    def softmax(self, x):\n",
    "        '''\n",
    "            softmax(x) = exp(x) / ∑exp(x)\n",
    "        '''\n",
    "        # Numerically stable with large exponentials\n",
    "        '''\n",
    "        in order to improve training stability, \n",
    "        deep neural networks typically use a numerically stable softmax,\n",
    "        which subtracts the max of the vector on which softmax is being performed\n",
    "        in order to ensure that the result does not blow up to infinity.\n",
    "        '''\n",
    "        exps = np.exp(x - x.max()) \n",
    "        return exps / np.sum(exps, axis=0)\n",
    "\n",
    "    def initialize(self):\n",
    "        # number of nodes in each layer\n",
    "        input_layer = self.sizes[0]\n",
    "        hidden_layer = self.sizes[1]\n",
    "        output_layer = self.sizes[2]\n",
    "\n",
    "        params = {\n",
    "            \"W1\": np.random.randn(hidden_layer, input_layer) * np.sqrt(1. / input_layer), # why??? \"* np.sqrt(1. / input_layer)\" why??\n",
    "            \"b1\": np.zeros((hidden_layer, 1)) * np.sqrt(1./input_layer),\n",
    "            \"W2\": np.random.randn(output_layer, hidden_layer) * np.sqrt(1. / hidden_layer), # Answer: Weight Initialization - Xavier initialization\n",
    "            \"b2\": np.zeros((output_layer, 1)) * np.sqrt(1./hidden_layer)\n",
    "        }\n",
    "        return params\n",
    "\n",
    "    def initialize_momentum_optimizer(self):\n",
    "        momentum_opt = {\n",
    "            \"W1\": np.zeros(self.params[\"W1\"].shape),\n",
    "            \"b1\": np.zeros(self.params[\"b1\"].shape),\n",
    "            \"W2\": np.zeros(self.params[\"W2\"].shape),\n",
    "            \"b2\": np.zeros(self.params[\"b2\"].shape)\n",
    "        }\n",
    "        return momentum_opt\n",
    "\n",
    "    def feed_forward(self, x):\n",
    "        '''\n",
    "            y = σ(wX + b)\n",
    "        '''\n",
    "        self.cache[\"X\"] = x\n",
    "        self.cache[\"Z1\"] = np.matmul(self.params['W1'], self.cache['X'].T) + self.params['b1']\n",
    "        self.cache[\"A1\"] = self.activation(self.cache[\"Z1\"])\n",
    "        self.cache[\"Z2\"] = np.matmul(self.params['W2'], self.cache[\"A1\"]) + self.params['b2']\n",
    "        self.cache[\"A2\"] = self.softmax(self.cache['Z2'])\n",
    "        return self.cache['A2']\n",
    "\n",
    "    def back_propagate(self, y, output):\n",
    "        '''\n",
    "            This is the backpropagation algorithm, for calculating the updates\n",
    "            of the neural network's parameters.\n",
    "\n",
    "            Note: There is a stability issue that causes warnings. This is \n",
    "                  caused  by the dot and multiply operations on the huge arrays.\n",
    "                  \n",
    "                  RuntimeWarning: invalid value encountered in true_divide\n",
    "                  RuntimeWarning: overflow encountered in exp\n",
    "                  RuntimeWarning: overflow encountered in square\n",
    "        '''\n",
    "        current_batch_size = y.shape[0]\n",
    "        dZ2 = output - y.T\n",
    "        dW2 = (1./current_batch_size) * np.matmul(dZ2, self.cache[\"A1\"].T)\n",
    "        db2 = (1./current_batch_size) * np.sum(dZ2, axis = 1, keepdims = True)\n",
    "\n",
    "        dA1 = np.matmul(self.params[\"W2\"].T, dZ2)\n",
    "        dZ1 = dA1 * self.activation(self.cache[\"Z1\"], derivative = True)\n",
    "        dW1 = (1./current_batch_size) * np.matmul(dZ1, self.cache[\"X\"])\n",
    "        db1 = (1./current_batch_size) * np.sum(dZ1, axis = 1, keepdims = True)\n",
    "\n",
    "        self.grads = {\"W1\": dW1, \"b1\":db1, \"W2\":dW2, \"b2\":db2}\n",
    "        return self.grads\n",
    "\n",
    "    def cross_entropy_loss(self, y, output):\n",
    "        '''\n",
    "            L(y, ŷ) = −∑ylog(ŷ).\n",
    "        '''\n",
    "        l_sum = np.sum(np.multiply(y.T, np.log(output)))\n",
    "        m = y.shape[0]\n",
    "        l = -(1./m) * l_sum\n",
    "    \n",
    "        return l\n",
    "\n",
    "    def optimize(self, l_rate=0.1, beta=.9):\n",
    "        '''\n",
    "            Stochatic Gradient Descent (SGD):\n",
    "            θ^(t+1) <- θ^t - η∇L(y, ŷ)\n",
    "            \n",
    "            Momentum:\n",
    "            v^(t+1) <- βv^t + (1-β)∇L(y, ŷ)^t\n",
    "            θ^(t+1) <- θ^t - ηv^(t+1)\n",
    "        '''\n",
    "        if self.optimizer == \"sgd\":\n",
    "            for key in self.params:\n",
    "                self.params[key] = self.params[key] - l_rate * self.grads[key]\n",
    "        elif self.optimizer == \"momentum\":\n",
    "            for key in self.params:\n",
    "                self.momentum_opt[key] = (beta * self.momentum_opt[key] + (1. - beta) * self.grads[key])\n",
    "                self.params[key] = self.params[key] - l_rate * self.momentum_opt[key]\n",
    "        else:\n",
    "            raise ValueError(\"Optimizer is currently not support, please use 'sgd' or 'momentum' instead.\")\n",
    "\n",
    "    def accuracy(self, y, output):\n",
    "        return np.mean(np.argmax(y, axis=-1) == np.argmax(output.T, axis = -1))\n",
    "\n",
    "    def train(self, x_train, y_train, x_test, y_test, epochs=10, \n",
    "              batch_size=64, optimizer='momentum', l_rate=0.1, beta=.9):\n",
    "        # Hyperparameters\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        num_batches = -(-x_train.shape[0] // self.batch_size)\n",
    "\n",
    "        # Initialize optimizer\n",
    "        self.optimizer = optimizer\n",
    "        if self.optimizer == 'momentum':\n",
    "            self.momentum_opt = self.initialize_momentum_optimizer()\n",
    "\n",
    "        start_time = time.time()\n",
    "        template = \"Epoch {}: {:.2f}s,train acc={:.2f}, train loss={:.2f}, test acc={:.2f}, test loss={:.2f}\"\n",
    "\n",
    "        # Train\n",
    "        for i in range(self.epochs):\n",
    "            # Shuffle\n",
    "            permutation = np.random.permutation(x_train.shape[0])\n",
    "            x_train_shuffled = x_train[permutation]\n",
    "            y_train_shuffled = y_train[permutation]\n",
    "\n",
    "            for j in range(num_batches):\n",
    "                # Batch\n",
    "                begin = j * self.batch_size\n",
    "                end = min(begin + self.batch_size, x_train.shape[0] - 1)\n",
    "                x = x_train_shuffled[begin:end]\n",
    "                y = y_train_shuffled[begin:end]\n",
    "\n",
    "                # Forward Propagation\n",
    "                output = self.feed_forward(x)\n",
    "                # Back propagation\n",
    "                grad = self.back_propagate(y, output)\n",
    "                # Optimize\n",
    "                self.optimize(l_rate=l_rate, beta=beta)\n",
    "\n",
    "            # Evaluate performance\n",
    "            # Training data\n",
    "            output = self.feed_forward(x_train)\n",
    "            train_acc = self.accuracy(y_train, output)\n",
    "            train_loss = self.cross_entropy_loss(y_train, output)\n",
    "            # Test data\n",
    "            output = self.feed_forward(x_test)\n",
    "            test_acc = self.accuracy(y_test, output)\n",
    "            test_loss = self.cross_entropy_loss(y_test, output)        \n",
    "            print(template.format(i+1, time.time()-start_time,train_acc, train_loss, test_acc, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09e4e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
